{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка-данных\" data-toc-modified-id=\"Подготовка-данных-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка данных</a></span><ul class=\"toc-item\"><li><span><a href=\"#Изучение-данных\" data-toc-modified-id=\"Изучение-данных-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Изучение данных</a></span></li><li><span><a href=\"#Предобработка-данных\" data-toc-modified-id=\"Предобработка-данных-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Предобработка данных</a></span><ul class=\"toc-item\"><li><span><a href=\"#Заполнение-пропусков\" data-toc-modified-id=\"Заполнение-пропусков-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Заполнение пропусков</a></span></li><li><span><a href=\"#Кодирование-признаков-OHE\" data-toc-modified-id=\"Кодирование-признаков-OHE-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Кодирование признаков <code>OHE</code></a></span></li><li><span><a href=\"#Признаки-и-целевые-значения.-Масштабирование-данных\" data-toc-modified-id=\"Признаки-и-целевые-значения.-Масштабирование-данных-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>Признаки и целевые значения. Масштабирование данных</a></span></li></ul></li><li><span><a href=\"#Итог-по-подготовке-данных\" data-toc-modified-id=\"Итог-по-подготовке-данных-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Итог по подготовке данных</a></span></li></ul></li><li><span><a href=\"#Исследование-задачи\" data-toc-modified-id=\"Исследование-задачи-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Исследование задачи</a></span><ul class=\"toc-item\"><li><span><a href=\"#Модель-Решающего-дерева\" data-toc-modified-id=\"Модель-Решающего-дерева-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Модель <code>Решающего дерева</code></a></span></li><li><span><a href=\"#Модель-Случайного-леса\" data-toc-modified-id=\"Модель-Случайного-леса-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Модель <code>Случайного леса</code></a></span></li><li><span><a href=\"#Модель-Логистической-регрессии\" data-toc-modified-id=\"Модель-Логистической-регрессии-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Модель <code>Логистической регрессии</code></a></span></li><li><span><a href=\"#Тестирование-лучшей-модели\" data-toc-modified-id=\"Тестирование-лучшей-модели-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Тестирование лучшей модели</a></span></li><li><span><a href=\"#Проверка-на-адекватность\" data-toc-modified-id=\"Проверка-на-адекватность-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Проверка на адекватность</a></span></li><li><span><a href=\"#Итог-по-первым-обученным-моделям\" data-toc-modified-id=\"Итог-по-первым-обученным-моделям-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Итог по первым обученным моделям</a></span></li></ul></li><li><span><a href=\"#Борьба-с-дисбалансом\" data-toc-modified-id=\"Борьба-с-дисбалансом-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Борьба с дисбалансом</a></span><ul class=\"toc-item\"><li><span><a href=\"#Балансировка-классов-и-масштабирование-новых-признаков\" data-toc-modified-id=\"Балансировка-классов-и-масштабирование-новых-признаков-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Балансировка классов и масштабирование новых признаков</a></span></li><li><span><a href=\"#Модель-Решающего-дерева\" data-toc-modified-id=\"Модель-Решающего-дерева-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Модель <code>Решающего дерева</code></a></span></li><li><span><a href=\"#Модель-Случайного-леса\" data-toc-modified-id=\"Модель-Случайного-леса-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Модель <code>Случайного леса</code></a></span></li><li><span><a href=\"#Модель-Логистической-регрессии\" data-toc-modified-id=\"Модель-Логистической-регрессии-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Модель <code>Логистической регрессии</code></a></span></li><li><span><a href=\"#Итоги-по-сбалансированному-обучению\" data-toc-modified-id=\"Итоги-по-сбалансированному-обучению-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Итоги по сбалансированному обучению</a></span></li></ul></li><li><span><a href=\"#Дополнительное-исследование\" data-toc-modified-id=\"Дополнительное-исследование-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Дополнительное исследование</a></span><ul class=\"toc-item\"><li><span><a href=\"#Кодирование-признаков-Ordinal-Encoding-и-подготовка-данных-к-обучению\" data-toc-modified-id=\"Кодирование-признаков-Ordinal-Encoding-и-подготовка-данных-к-обучению-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Кодирование признаков <code>Ordinal Encoding</code> и подготовка данных к обучению</a></span></li><li><span><a href=\"#Обучение-на-новых-данных\" data-toc-modified-id=\"Обучение-на-новых-данных-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Обучение на новых данных</a></span></li></ul></li><li><span><a href=\"#Тестирование-моделей\" data-toc-modified-id=\"Тестирование-моделей-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Тестирование моделей</a></span></li><li><span><a href=\"#Чек-лист-готовности-проекта\" data-toc-modified-id=\"Чек-лист-готовности-проекта-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Чек-лист готовности проекта</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отток клиентов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.\n",
    "\n",
    "Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Вам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. \n",
    "\n",
    "Постройте модель с предельно большим значением *F1*-меры. Чтобы сдать проект успешно, нужно довести метрику до 0.59. Проверьте *F1*-меру на тестовой выборке самостоятельно.\n",
    "\n",
    "Дополнительно измеряйте *AUC-ROC*, сравнивайте её значение с *F1*-мерой.\n",
    "\n",
    "Источник данных: [https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling](https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Изучение данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**В данном проекте, мы решаем задачу классификации, а значит можем сразу импортировать модели и метрики необходимые для данной задачи.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# импортируем необходимые модели\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# импортируем методы необходимые для подготовки данных к исследованию\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "\n",
    "# импортируем необходимые для нашей задачи метрики\n",
    "from sklearn.metrics import f1_score, roc_auc_score, recall_score\n",
    "\n",
    "# добавим возможность создавать случайные модели\n",
    "from random import randint\n",
    "\n",
    "# выведу это лучше отдельно\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>15574012</td>\n",
       "      <td>Chu</td>\n",
       "      <td>645</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>8.0</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>15592531</td>\n",
       "      <td>Bartlett</td>\n",
       "      <td>822</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>15656148</td>\n",
       "      <td>Obinna</td>\n",
       "      <td>376</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>15792365</td>\n",
       "      <td>He</td>\n",
       "      <td>501</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>4.0</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>15592389</td>\n",
       "      <td>H?</td>\n",
       "      <td>684</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "5          6    15574012       Chu          645     Spain    Male   44   \n",
       "6          7    15592531  Bartlett          822    France    Male   50   \n",
       "7          8    15656148    Obinna          376   Germany  Female   29   \n",
       "8          9    15792365        He          501    France    Male   44   \n",
       "9         10    15592389        H?          684    France    Male   27   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "5     8.0  113755.78              2          1               0   \n",
       "6     7.0       0.00              2          1               1   \n",
       "7     4.0  115046.74              4          1               0   \n",
       "8     4.0  142051.07              2          0               1   \n",
       "9     2.0  134603.88              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  \n",
       "5        149756.71       1  \n",
       "6         10062.80       0  \n",
       "7        119346.88       1  \n",
       "8         74940.50       0  \n",
       "9         71725.73       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Посмотрим на наши данные\n",
    "data = pd.read_csv('/datasets/Churn.csv')\n",
    "display(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    7963\n",
      "1    2037\n",
      "Name: Exited, dtype: int64\n",
      "Процент ушедших клиентов: 20.369999999999997, оставшихся клиентов: 79.63 \n"
     ]
    }
   ],
   "source": [
    "# Посмотрим сколько клиентов ушло и сколько осталось\n",
    "print(data['Exited'].value_counts())\n",
    "print('Процент ушедших клиентов: {0}, оставшихся клиентов: {1} '. format(data['Exited'].value_counts()[1] / len(data) * 100, data['Exited'].value_counts()[0] / len(data) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Исходя из полученной информации выше получается, что наши классы не сбалансированны. Количество оставшихся клиентов в 4 раза больше чем количество ушедших, необходимо будет произвести так называемый `upsampling` - увеличить нашу выборку.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15695872    1\n",
      "15801062    1\n",
      "15682268    1\n",
      "15647453    1\n",
      "15684319    1\n",
      "           ..\n",
      "15629677    1\n",
      "15773039    1\n",
      "15766896    1\n",
      "15719793    1\n",
      "15812607    1\n",
      "Name: CustomerId, Length: 10000, dtype: int64 | уникальные [1]\n",
      "Smith       32\n",
      "Martin      29\n",
      "Scott       29\n",
      "Walker      28\n",
      "Brown       26\n",
      "            ..\n",
      "McEncroe     1\n",
      "Schatz       1\n",
      "Bayley       1\n",
      "Le Grand     1\n",
      "Lipton       1\n",
      "Name: Surname, Length: 2932, dtype: int64 | уникальные [32 29 28 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10  9  8  7  6\n",
      "  5  4  3  2  1]\n",
      "France     5014\n",
      "Germany    2509\n",
      "Spain      2477\n",
      "Name: Geography, dtype: int64 | уникальные [5014 2509 2477]\n",
      "Male      5457\n",
      "Female    4543\n",
      "Name: Gender, dtype: int64 | уникальные [5457 4543]\n"
     ]
    }
   ],
   "source": [
    "# Посмотрим на столбцы \"CustomerId\", \"Surname\", \"Geography\" и \"Gender\"\n",
    "\n",
    "for row in [\"CustomerId\", \"Surname\", \"Geography\", \"Gender\"]:\n",
    "    print(data[row].value_counts(),'| уникальные', data[row].value_counts().unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Изучая информацию выше, можем прийти к выводу, что столбец `CustomerId`, не несёт для решения нашей задачи никакого смысла, так как каждая строка новый пользователь (хоть это и логично из условия, но решил проверить). В итоге, этот столбец и `RowNumber` можем смело пропустить. Стоит также отметить, что столбец `Surname` содержит фамилии клиентов. Однако, каждая строка представляет собой нового клиента, а здравый смысл подсказывает, что фамилия клиента не должна влият на его решение остаться в банке или нет)), значит данный столбец тоже можно убрать из данных.***\n",
    "\n",
    "P.S.: Фамилии клентов можно добавить уже в конце проекта для дополнительного исследования, возможно сможем получить интересные результаты. Хоть это и не логично)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "France     5014\n",
      "Germany    2509\n",
      "Spain      2477\n",
      "Name: Geography, dtype: int64\n",
      "Male      5457\n",
      "Female    4543\n",
      "Name: Gender, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cтоит посмотреть также и на столбцы \"Geography\" и \"Gender\"\n",
    "for row in [\"Geography\", \"Gender\"]:\n",
    "    print(data[row].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Данные из этих столбцов скорее всего также могут вносить свой вклад при обучении моделей, а значит их надо привезти к числовому виду перед построением моделей.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Прежде чем двигаться дальше, проверим нет ли пропусков в данных.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RowNumber            0\n",
      "CustomerId           0\n",
      "Surname              0\n",
      "CreditScore          0\n",
      "Geography            0\n",
      "Gender               0\n",
      "Age                  0\n",
      "Tenure             909\n",
      "Balance              0\n",
      "NumOfProducts        0\n",
      "HasCrCard            0\n",
      "IsActiveMember       0\n",
      "EstimatedSalary      0\n",
      "Exited               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Как можем наблюдать, пропуски есть только в столбце `Tenure` в нём содержится информация о том сколько лет человек является клиентом банка. Данные пропуски стоит заполнить, так как подобные данные необходимы нам при построении моделей.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Заполнение пропусков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Заполнять пропуски будем медианными значениями. Перед этим найдём эти значения для групп данных (разнесённых по странам и полу).**\n",
    "\n",
    "P.S.: Мне кажется, подобный подход позволит более точно заполнить пропуски."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Gender</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Geography</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Germany</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spain</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Gender     Female  Male\n",
       "Geography              \n",
       "France        5.0   5.0\n",
       "Germany       5.0   5.0\n",
       "Spain         5.0   5.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data.pivot_table(index='Geography', columns='Gender', values='Tenure', aggfunc='median'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Получили весьма интересный результат, все усреднённые значения равны 5 годам, значит просто заменим все пропуски на пять лет)).***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Уберём пропуски в данных\n",
    "data['Tenure'] = data['Tenure'].fillna(5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Кодирование признаков `OHE`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Как было сказано раннее, столбцы `Geography` и `Gender` также необходимы для построения моделей, а значит их надо привезти к числовому виду. Для решения этой проблемы мы изучили две техники: - прямое кодирование (или `One-Hot Encoding, OHE`) и порядковое кодирование (или `Ordinal Encoding`). Ввиду того, что нам мы будем обучать модели, основанные на решающих деревьях, а также на логистической регрессии. То для кодирования признаков применим прямое кодирование, так как оно подходит для всех моделей.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>645</td>\n",
       "      <td>44</td>\n",
       "      <td>8.0</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>822</td>\n",
       "      <td>50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>376</td>\n",
       "      <td>29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>501</td>\n",
       "      <td>44</td>\n",
       "      <td>4.0</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>684</td>\n",
       "      <td>27</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42     2.0       0.00              1          1   \n",
       "1          608   41     1.0   83807.86              1          0   \n",
       "2          502   42     8.0  159660.80              3          1   \n",
       "3          699   39     1.0       0.00              2          0   \n",
       "4          850   43     2.0  125510.82              1          1   \n",
       "5          645   44     8.0  113755.78              2          1   \n",
       "6          822   50     7.0       0.00              2          1   \n",
       "7          376   29     4.0  115046.74              4          1   \n",
       "8          501   44     4.0  142051.07              2          0   \n",
       "9          684   27     2.0  134603.88              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
       "0               1        101348.88       1                  0   \n",
       "1               1        112542.58       0                  0   \n",
       "2               0        113931.57       1                  0   \n",
       "3               0         93826.63       0                  0   \n",
       "4               1         79084.10       0                  0   \n",
       "5               0        149756.71       1                  0   \n",
       "6               1         10062.80       0                  0   \n",
       "7               0        119346.88       1                  1   \n",
       "8               1         74940.50       0                  0   \n",
       "9               1         71725.73       0                  0   \n",
       "\n",
       "   Geography_Spain  Gender_Male  \n",
       "0                0            0  \n",
       "1                1            0  \n",
       "2                0            0  \n",
       "3                0            0  \n",
       "4                1            0  \n",
       "5                1            1  \n",
       "6                0            1  \n",
       "7                0            0  \n",
       "8                0            1  \n",
       "9                0            1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Произведём прямое кодирование признаков\n",
    "data_ohe = data.drop(['CustomerId', 'Surname', 'RowNumber'], axis=1)\n",
    "data_ohe = pd.get_dummies(data_ohe, drop_first=True)\n",
    "\n",
    "#выведем получившийся фрейм на экран\n",
    "display(data_ohe.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Признаки и целевые значения. Масштабирование данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Прежде чем приступить к дальнейшему обучению моделей, отделим признаки от целевых значений, а также приведём все признаки к единому масштабу, дабы избежать, влияния слишком больших значений.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fast_ml in /opt/conda/lib/python3.9/site-packages (3.68)\r\n"
     ]
    }
   ],
   "source": [
    "# Разделим сразу же на обучающую, валидационную и тестовую выборки в пропорции 3:1:1\n",
    "!pip install fast_ml\n",
    "\n",
    "from fast_ml.model_development import train_valid_test_split\n",
    "\n",
    "features_train, target_train, features_valid,  target_valid, features_test,  target_test = train_valid_test_split(data_ohe, \n",
    "                                        target = 'Exited', train_size=0.6, valid_size=0.2, test_size=0.2, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пока уберу проделанную работу в другой тип ячеек, чтобы код не падал\n",
    "\n",
    "**------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Уберём лишнее из фрейма\n",
    "data_ohe = data.drop(['CustomerId', 'Surname', 'RowNumber'], axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Добавлю установку в этом месте, чтобы понимать для чего она вообще нужна,\n",
    "# а то платформа действительно ругается страшными словами\n",
    "!pip install scikit-learn==1.1.3"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "names_features = features_train.select_dtypes(include='object').columns.to_list()\n",
    "display(names_features)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# создаём кодировщик\n",
    "encoder_ohe = OneHotEncoder(drop='First', handle_unknown='ignore', sparse=False)\n",
    "\n",
    "# подготовим обучающие признаки\n",
    "\n",
    "# обучим кодировщик\n",
    "encoder_ohe.fit(features_train[names_features])\n",
    "\n",
    "# добавим закодированные признаки в данные\n",
    "features_train[encoder_ohe.get_features_name_out()] = encoder_ohe.transform(features_train[names_features])\n",
    "\n",
    "# подготовим валидационные признаки\n",
    "features_valid[encoder_ohe.get_features_name_out()] = encoder_ohe.transform(features_valid[names_features])\n",
    "\n",
    "# подготовим тестовые признаки\n",
    "features_test[encoder_ohe.get_features_name_out()] = encoder_ohe.transform(features_test[names_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**----------------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CreditScore',\n",
       " 'Age',\n",
       " 'Tenure',\n",
       " 'Balance',\n",
       " 'NumOfProducts',\n",
       " 'HasCrCard',\n",
       " 'IsActiveMember',\n",
       " 'EstimatedSalary',\n",
       " 'Geography_Germany',\n",
       " 'Geography_Spain',\n",
       " 'Gender_Male']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "names_features = features_train.columns.to_list()\n",
    "display(names_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Произведём масштабирование данных\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[names_features])\n",
    "\n",
    "features_train[names_features] = scaler.transform(features_train[names_features])\n",
    "features_valid[names_features] = scaler.transform(features_valid[names_features])\n",
    "features_test[names_features] = scaler.transform(features_test[names_features]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7479</th>\n",
       "      <td>-0.886751</td>\n",
       "      <td>-0.373192</td>\n",
       "      <td>1.082277</td>\n",
       "      <td>1.232271</td>\n",
       "      <td>-0.891560</td>\n",
       "      <td>0.642466</td>\n",
       "      <td>-1.055187</td>\n",
       "      <td>-0.187705</td>\n",
       "      <td>-0.572475</td>\n",
       "      <td>1.728977</td>\n",
       "      <td>0.907278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3411</th>\n",
       "      <td>0.608663</td>\n",
       "      <td>-0.183385</td>\n",
       "      <td>1.082277</td>\n",
       "      <td>0.600563</td>\n",
       "      <td>-0.891560</td>\n",
       "      <td>-1.556504</td>\n",
       "      <td>-1.055187</td>\n",
       "      <td>-0.333945</td>\n",
       "      <td>-0.572475</td>\n",
       "      <td>-0.578377</td>\n",
       "      <td>-1.102198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6027</th>\n",
       "      <td>2.052152</td>\n",
       "      <td>0.480939</td>\n",
       "      <td>-0.737696</td>\n",
       "      <td>1.027098</td>\n",
       "      <td>0.830152</td>\n",
       "      <td>-1.556504</td>\n",
       "      <td>0.947699</td>\n",
       "      <td>1.503095</td>\n",
       "      <td>1.746802</td>\n",
       "      <td>-0.578377</td>\n",
       "      <td>0.907278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>-1.457915</td>\n",
       "      <td>-1.417129</td>\n",
       "      <td>0.354288</td>\n",
       "      <td>-1.233163</td>\n",
       "      <td>0.830152</td>\n",
       "      <td>0.642466</td>\n",
       "      <td>-1.055187</td>\n",
       "      <td>-1.071061</td>\n",
       "      <td>-0.572475</td>\n",
       "      <td>-0.578377</td>\n",
       "      <td>0.907278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3716</th>\n",
       "      <td>0.130961</td>\n",
       "      <td>-1.132419</td>\n",
       "      <td>-1.101690</td>\n",
       "      <td>1.140475</td>\n",
       "      <td>-0.891560</td>\n",
       "      <td>-1.556504</td>\n",
       "      <td>-1.055187</td>\n",
       "      <td>1.524268</td>\n",
       "      <td>1.746802</td>\n",
       "      <td>-0.578377</td>\n",
       "      <td>-1.102198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4478</th>\n",
       "      <td>-1.073677</td>\n",
       "      <td>-0.752805</td>\n",
       "      <td>-0.373701</td>\n",
       "      <td>-1.233163</td>\n",
       "      <td>0.830152</td>\n",
       "      <td>-1.556504</td>\n",
       "      <td>0.947699</td>\n",
       "      <td>-1.278361</td>\n",
       "      <td>-0.572475</td>\n",
       "      <td>-0.578377</td>\n",
       "      <td>0.907278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4094</th>\n",
       "      <td>-1.447531</td>\n",
       "      <td>-0.942612</td>\n",
       "      <td>1.810266</td>\n",
       "      <td>-1.233163</td>\n",
       "      <td>0.830152</td>\n",
       "      <td>-1.556504</td>\n",
       "      <td>0.947699</td>\n",
       "      <td>-1.281307</td>\n",
       "      <td>-0.572475</td>\n",
       "      <td>-0.578377</td>\n",
       "      <td>0.907278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492</th>\n",
       "      <td>0.027113</td>\n",
       "      <td>0.575842</td>\n",
       "      <td>-0.009707</td>\n",
       "      <td>-0.310229</td>\n",
       "      <td>-0.891560</td>\n",
       "      <td>-1.556504</td>\n",
       "      <td>0.947699</td>\n",
       "      <td>-0.903158</td>\n",
       "      <td>-0.572475</td>\n",
       "      <td>-0.578377</td>\n",
       "      <td>-1.102198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2177</th>\n",
       "      <td>0.151731</td>\n",
       "      <td>-1.417129</td>\n",
       "      <td>-0.373701</td>\n",
       "      <td>-1.233163</td>\n",
       "      <td>0.830152</td>\n",
       "      <td>-1.556504</td>\n",
       "      <td>0.947699</td>\n",
       "      <td>-1.128539</td>\n",
       "      <td>-0.572475</td>\n",
       "      <td>-0.578377</td>\n",
       "      <td>-1.102198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4578</th>\n",
       "      <td>0.400966</td>\n",
       "      <td>-0.088482</td>\n",
       "      <td>-1.465685</td>\n",
       "      <td>-1.233163</td>\n",
       "      <td>0.830152</td>\n",
       "      <td>-1.556504</td>\n",
       "      <td>-1.055187</td>\n",
       "      <td>-0.949841</td>\n",
       "      <td>-0.572475</td>\n",
       "      <td>-0.578377</td>\n",
       "      <td>0.907278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore       Age    Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "7479    -0.886751 -0.373192  1.082277  1.232271      -0.891560   0.642466   \n",
       "3411     0.608663 -0.183385  1.082277  0.600563      -0.891560  -1.556504   \n",
       "6027     2.052152  0.480939 -0.737696  1.027098       0.830152  -1.556504   \n",
       "1247    -1.457915 -1.417129  0.354288 -1.233163       0.830152   0.642466   \n",
       "3716     0.130961 -1.132419 -1.101690  1.140475      -0.891560  -1.556504   \n",
       "...           ...       ...       ...       ...            ...        ...   \n",
       "4478    -1.073677 -0.752805 -0.373701 -1.233163       0.830152  -1.556504   \n",
       "4094    -1.447531 -0.942612  1.810266 -1.233163       0.830152  -1.556504   \n",
       "3492     0.027113  0.575842 -0.009707 -0.310229      -0.891560  -1.556504   \n",
       "2177     0.151731 -1.417129 -0.373701 -1.233163       0.830152  -1.556504   \n",
       "4578     0.400966 -0.088482 -1.465685 -1.233163       0.830152  -1.556504   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Geography_Germany  Geography_Spain  \\\n",
       "7479       -1.055187        -0.187705          -0.572475         1.728977   \n",
       "3411       -1.055187        -0.333945          -0.572475        -0.578377   \n",
       "6027        0.947699         1.503095           1.746802        -0.578377   \n",
       "1247       -1.055187        -1.071061          -0.572475        -0.578377   \n",
       "3716       -1.055187         1.524268           1.746802        -0.578377   \n",
       "...              ...              ...                ...              ...   \n",
       "4478        0.947699        -1.278361          -0.572475        -0.578377   \n",
       "4094        0.947699        -1.281307          -0.572475        -0.578377   \n",
       "3492        0.947699        -0.903158          -0.572475        -0.578377   \n",
       "2177        0.947699        -1.128539          -0.572475        -0.578377   \n",
       "4578       -1.055187        -0.949841          -0.572475        -0.578377   \n",
       "\n",
       "      Gender_Male  \n",
       "7479     0.907278  \n",
       "3411    -1.102198  \n",
       "6027     0.907278  \n",
       "1247     0.907278  \n",
       "3716    -1.102198  \n",
       "...           ...  \n",
       "4478     0.907278  \n",
       "4094     0.907278  \n",
       "3492    -1.102198  \n",
       "2177    -1.102198  \n",
       "4578     0.907278  \n",
       "\n",
       "[6000 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Посмотрим на масштабированные признаки\n",
    "display(features_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Признаки приведены к одной размерности, теперь с ними можно работать.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Итог по подготовке данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- При изучении данных было отмечено наличие несбалансированности целевых классов, наличие пропусков, а также признаков которые необходимо закодировать и масштабировать.\n",
    "- Была произведена предобработка данных в ходе которой исправили особенности в данных, которые могли помешать обучению моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследование задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**На данном этапе приступим к обучению моделей. Будем обучать модели: `Решающее дерево`, `Случайный лес` и `Логистическая регрессия`. Для начала, обучение проведём на основе несбалансированных данных. Вычислим наилучшую модель и получим конечную оценку на тестовых данных.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель `Решающего дерева`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Начнём нашу работу с модели, основанной на `дереве решений`. Это наверное самая простая модель, в которой будем регулировать всего-лишь один гипер-параметр и это глубина дерева. По пробуем сделать модели с разной глубиной и выбирем ту, что получит наилучший результат.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшая модель: DecisionTreeClassifier(max_depth=6, random_state=12345), значение метрики F1 равно: 0.57, метрики ROC AUC: 0.816.\n"
     ]
    }
   ],
   "source": [
    "# Будем перебирать в цикле различную глубину деревьев, и сохраним ту модель, которая даст наилучший результат\n",
    "# Добавим для эксперимента большую глубину до 20\n",
    "\n",
    "best_model_Decision_Tree = None\n",
    "best_result_valid = 0\n",
    "best_result_roc_auc = 0\n",
    "\n",
    "for depth in range(1, 21):\n",
    "    \n",
    "    model = DecisionTreeClassifier(random_state=12345, max_depth=depth) # определяем модель с заданной глубиной дерева\n",
    "    \n",
    "    model.fit(features_train, target_train) # обучаем модель\n",
    "    \n",
    "    predictions_valid = model.predict(features_valid) # получаем предсказания модели\n",
    "    \n",
    "    result_f1 = f1_score(target_valid, predictions_valid) # подсчитываем качество модели F1 - мерой\n",
    "    \n",
    "    # расчитаем метрику ROC_AUC\n",
    "    probabilities = model.predict_proba(features_valid)\n",
    "    result_roc_auc = roc_auc_score(target_valid, probabilities[:, 1])\n",
    "    \n",
    "    if result_f1 > best_result_valid:\n",
    "        best_model_Decision_Tree = model\n",
    "        best_result_valid = result_f1\n",
    "        best_result_roc_auc = result_roc_auc\n",
    "\n",
    "print('Наилучшая модель: {0}, значение метрики F1 равно: {1}, метрики ROC AUC: {2}.'. \n",
    "      format(best_model_Decision_Tree, round(best_result_valid, 3), round(best_result_roc_auc, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Неплохой результат получился на первой и самой простой модели). Учитывая, что в целях проекта необходимо добиться показателя 0.59, а мы имеем 0.57.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель `Случайного леса`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Модель в основе которой лежит `случайный лес`, уже является более сложной и значительно устойчивее, так как конечное решение принимается не одним деревом, а сразу несколькими \"на основе голосования\", что потенциально даёт результат лучше.** При построении данной модели будем регулировать уже не только глубину деревьев, но и их количество. Также, в результате сохраним полученную модель в отдельную переменную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшая модель: RandomForestClassifier(max_depth=14, n_estimators=15, random_state=12345), значение метрики F1 равно: 0.594, метрики ROC AUC: 0.831.\n"
     ]
    }
   ],
   "source": [
    "best_model_Random_Forest = None\n",
    "best_result_valid = 0\n",
    "best_result_roc_auc = 0\n",
    "\n",
    "for depth in range(1, 21):\n",
    "    for est in range(5, 101, 5):\n",
    "        \n",
    "        # определяем модель с заданными количеством и глубиной деревьев\n",
    "        model = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth)\n",
    "\n",
    "        model.fit(features_train, target_train) # обучаем модель\n",
    "\n",
    "        predictions_valid = model.predict(features_valid) # получаем предсказания модели\n",
    "\n",
    "        result_f1 = f1_score(target_valid, predictions_valid) # подсчитываем качество модели f1-мерой\n",
    "        \n",
    "        # расчитаем метрику ROC_AUC\n",
    "        probabilities = model.predict_proba(features_valid)\n",
    "        result_roc_auc = roc_auc_score(target_valid, probabilities[:, 1])\n",
    "        \n",
    "\n",
    "        if result_f1 > best_result_valid:\n",
    "            best_model_Random_Forest = model\n",
    "            best_result_valid = result_f1\n",
    "            best_result_roc_auc = result_roc_auc\n",
    "\n",
    "print('Наилучшая модель: {0}, значение метрики F1 равно: {1}, метрики ROC AUC: {2}.'. \n",
    "      format(best_model_Random_Forest, round(best_result_valid, 3), round(best_result_roc_auc, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Модель `Случайного леса` превысила заданное в условии задачи значение качества метрики F1-меры 0.59. Если следующая модель не покажет  результат лучше, то проверим ее на тестовых данных.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель `Логистической регрессии`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Логистическая регрессия самая уникальная из представленных нам на данном этапе. Она имеет меньше всего параметров, и является наиболее устойчивой к переобучению. При построении модели возьмём число итераций не больше 10 000, а также будем оперировать решающими алгоритмами, которые есть в данной модели.** На счёт решающих алгоритмов, просто интересно посмотреть какие получим в итоге результаты меняя различные алгоритмы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель: LogisticRegression(max_iter=10000, random_state=12345, solver='liblinear'), значение F1-меры равно: 0.331, ROC_AUC: 0.759\n",
      "Модель: LogisticRegression(max_iter=10000, random_state=12345, solver='newton-cg'), значение F1-меры равно: 0.331, ROC_AUC: 0.759\n",
      "Модель: LogisticRegression(max_iter=10000, random_state=12345), значение F1-меры равно: 0.331, ROC_AUC: 0.759\n",
      "Модель: LogisticRegression(max_iter=10000, random_state=12345, solver='sag'), значение F1-меры равно: 0.331, ROC_AUC: 0.759\n",
      "Модель: LogisticRegression(max_iter=10000, random_state=12345, solver='saga'), значение F1-меры равно: 0.331, ROC_AUC: 0.759\n",
      "\n",
      "Наилучшая модель: LogisticRegression(max_iter=10000, random_state=12345, solver='liblinear'), значение метрики F1 равно: 0.331, метрики ROC AUC: 0.759.\n"
     ]
    }
   ],
   "source": [
    "# Для данной модели будем перебирать различные решающие алгоритмы.\n",
    "\n",
    "best_model_LogisticRegression = None\n",
    "best_result_valid = 0\n",
    "best_result_roc_auc = 0\n",
    "algoritms = ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "\n",
    "\n",
    "for alg in algoritms:\n",
    "\n",
    "    # определяем модель с заданным решающим алгоритмом и количеством итераций\n",
    "    model = LogisticRegression(random_state=12345, solver=alg, max_iter=10000)\n",
    "\n",
    "    model.fit(features_train, target_train) # обучаем модель\n",
    "\n",
    "    predictions_valid = model.predict(features_valid) # получаем предсказания модели\n",
    "\n",
    "    result_f1 = f1_score(target_valid, predictions_valid) # подсчитываем качество модели f1-мерой\n",
    "        \n",
    "    # расчитаем метрику ROC_AUC\n",
    "    probabilities = model.predict_proba(features_valid)\n",
    "    result_roc_auc = roc_auc_score(target_valid, probabilities[:, 1])\n",
    "    \n",
    "    print('Модель: {0}, значение F1-меры равно: {1}, ROC_AUC: {2}'. format(model, round(result_f1, 3), round(result_roc_auc, 3)))\n",
    "\n",
    "    if result_f1 > best_result_valid:\n",
    "        best_model_Logistic_Regression = model\n",
    "        best_result_valid = result_f1\n",
    "        best_result_roc_auc = result_roc_auc\n",
    "\n",
    "print()\n",
    "print('Наилучшая модель: {0}, значение метрики F1 равно: {1}, метрики ROC AUC: {2}.'. \n",
    "          format(best_model_Logistic_Regression, round(best_result_valid, 3), round(best_result_roc_auc, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Модель `Логистической регрессии` пока что показывает самый низкий результат. Всего 0.331!! Также стоит отметить, что все решающие алгоритмы дали один и тот же результат, что не много удивляет. На данном этапе непонятно почему так получилось.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестирование лучшей модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Лучшей моделью стал `Случайный лес`, который на валидационной выборке показал самый высокий результат 0.588. Полученная в результате модель имеет следующие параметры: глубина деревьев - 18, количество деревьев - 50. Теперь проверим нашу модель на тестовых данных.**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Вычислим предсказания модели\n",
    "predictions_test = best_model_Random_Forest.predict(features_test_scaled)\n",
    "\n",
    "# вычислим значение F1-меры для тестовой выборки\n",
    "f1_score_test = f1_score(target_test, predictions_test)\n",
    "print('Значение F1-меры на тестовых данных равно:', round(f1_score_test, 3))\n",
    "\n",
    "# вычислим значение ROC_AUC для тестовой выборки\n",
    "roc_auc_score_test = roc_auc_score(target_test, predictions_test)\n",
    "print('Значение ROC_AUC на тестовых данных равно:', round(roc_auc_score_test, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка на адекватность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создадим cлучайную модель, которая будет состоять из массива случайных целевых значений. И вычислим значение нашей метрики.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим случайную модель (на основе функции)\n",
    "def random_model(len_arr):\n",
    "    predictions = []\n",
    "    for pred in range(0, len_arr):\n",
    "        predictions.append(randint(0, 1))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Будем запускать случайную модель 10000 раз и сразу расчитывать значение F1-меры. Затем на основе подсчитанных соотношений возьмем среднее и сравним его с моделью `Случайного леса`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее значение качества случайной модели равно: 0.297\n"
     ]
    }
   ],
   "source": [
    "# Подсчитаем среднее качество случайной модели\n",
    "accuracy_random_array = []\n",
    "for i in range(0, 1000):\n",
    "    accuracy_random_array.append(f1_score(target_test, random_model(len(target_test))))\n",
    "    \n",
    "print('Среднее значение качества случайной модели равно:', round(np.mean(accuracy_random_array), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Просто интересно, построим график распределения случайных значений качества\n",
    "plt.plot(accuracy_random_array)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Как можем видеть качество модели `Логистической регрессии` 0.311 сопоставимо  со случайной моделью ~ 0.3, уже на данном этапе можем смело отсеять данную модель.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3491539413949649"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_model = DummyClassifier(strategy='constant', constant=1)\n",
    "dummy_model.fit(features_train, target_train)\n",
    "f1_score(dummy_model.predict(features_test), target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Итог по первым обученным моделям"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) По результатами \"серьёзного\" отбора лучшей моделью на данном этапе стал `Случайный лес`, показавший результат 0.551.\n",
    "\n",
    "2) Проведя проверку на адекватность выяснили, что только модель `Логистической регрессии` не прошла данную проверку. Деревья вполне адекватные) и существенно качественнее случайной модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Борьба с дисбалансом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Балансировка классов и масштабирование новых признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пришло время провести балансировку наших данных. Для этого в обучающих данных наростим количество клиентов покинувших банк.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для упрощения жизни, возьмём функцию \"апсемплинга\", предложенную в одном из уроков\n",
    "# данная функция очень качественно \"наращивает\" обучающую выборку.\n",
    "\n",
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    \n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=12345)\n",
    "    \n",
    "    return features_upsampled, target_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сбалансируем нашу выборку применив функцию upsample, \n",
    "# так как разница между классами в 4 раза, то и число повторений сделаем такое же\n",
    "features_upsampled, target_upsampled = upsample(features_train, target_train, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4804\n",
      "1    4784\n",
      "Name: Exited, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# проверим насколько привильно балансировка отработала\n",
    "print(target_upsampled.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отмасштабируем новый массив признаков\n",
    "scaler.fit(features_upsampled)\n",
    "\n",
    "features_upsampled_scaled = scaler.transform(features_upsampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Итак, наши классы сбалансированны и приведены к одному масштабу, теперь можем опять приступить к обучению моделей.*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель `Решающего дерева`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшая модель: DecisionTreeClassifier(max_depth=5, random_state=12345), значение метрики F1 равно: 0.579, метрики ROC AUC: 0.832.\n"
     ]
    }
   ],
   "source": [
    "# Повоторим процедуру проделанную ранее, только теперь со сбалансированными данными\n",
    "\n",
    "best_model_Decision_Tree_upsampled = None\n",
    "best_result_valid = 0\n",
    "best_result_roc_auc = 0\n",
    "\n",
    "for depth in range(1, 21):\n",
    "    \n",
    "    model = DecisionTreeClassifier(random_state=12345, max_depth=depth) # определяем модель с заданной глубиной дерева\n",
    "    \n",
    "    model.fit(features_upsampled_scaled, target_upsampled) # обучаем модель\n",
    "    \n",
    "    predictions_valid = model.predict(features_valid) # получаем предсказания модели\n",
    "    \n",
    "    result_f1 = f1_score(target_valid, predictions_valid) # подсчитываем качество модели F1 - мерой\n",
    "        \n",
    "    # расчитаем метрику ROC_AUC\n",
    "    probabilities = model.predict_proba(features_valid)\n",
    "    result_roc_auc = roc_auc_score(target_valid, probabilities[:, 1])\n",
    "    \n",
    "    if result_f1 > best_result_valid:\n",
    "        best_model_Decision_Tree_upsampled = model\n",
    "        best_result_valid = result_f1\n",
    "        best_result_roc_auc = result_roc_auc\n",
    "\n",
    "print('Наилучшая модель: {0}, значение метрики F1 равно: {1}, метрики ROC AUC: {2}.'. \n",
    "      format(best_model_Decision_Tree_upsampled, round(best_result_valid, 3), round(best_result_roc_auc, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Модель стала лучше. Ранее значение F1-меры было 0.57, а теперь 0.579. Прогресс на лицо, но все-равно слишком низкое качество.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель `Случайного леса`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшая модель: RandomForestClassifier(max_depth=11, random_state=12345), значение метрики F1 равно: 0.623, метрики ROC AUC: 0.846.\n"
     ]
    }
   ],
   "source": [
    "best_model_Random_Forest_upsampled = None\n",
    "best_result_valid = 0\n",
    "best_result_roc_auc = 0\n",
    "\n",
    "for depth in range(1, 21):\n",
    "    for est in range(5, 101, 5):\n",
    "        \n",
    "        # определяем модель с заданными количеством и глубиной деревьев\n",
    "        model = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth)\n",
    "\n",
    "        model.fit(features_upsampled_scaled, target_upsampled) # обучаем модель\n",
    "\n",
    "        predictions_valid = model.predict(features_valid) # получаем предсказания модели\n",
    "\n",
    "        result_f1 = f1_score(target_valid, predictions_valid) # подсчитываем качество модели f1-мерой\n",
    "        \n",
    "        # расчитаем метрику ROC_AUC\n",
    "        probabilities = model.predict_proba(features_valid)\n",
    "        result_roc_auc = roc_auc_score(target_valid, probabilities[:, 1])\n",
    "\n",
    "        if result_f1 > best_result_valid:\n",
    "            best_model_Random_Forest_upsampled = model\n",
    "            best_result_valid = result_f1\n",
    "            best_result_roc_auc = result_roc_auc\n",
    "\n",
    "print('Наилучшая модель: {0}, значение метрики F1 равно: {1}, метрики ROC AUC: {2}.'. \n",
    "      format(best_model_Random_Forest_upsampled, round(best_result_valid, 3), round(best_result_roc_auc, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Отличный результат получен благодаря `Случайному лесу`. Данная модель снова претендует на звание лучшей)). Ранее был результат 0.594, после балансировки уже 0.623.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель `Логистической регрессии`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель: LogisticRegression(max_iter=10000, random_state=12345, solver='liblinear'), значение F1-меры равно: 0.476, ROC_AUC: 0.763\n",
      "Модель: LogisticRegression(max_iter=10000, random_state=12345, solver='newton-cg'), значение F1-меры равно: 0.476, ROC_AUC: 0.763\n",
      "Модель: LogisticRegression(max_iter=10000, random_state=12345), значение F1-меры равно: 0.476, ROC_AUC: 0.763\n",
      "Модель: LogisticRegression(max_iter=10000, random_state=12345, solver='sag'), значение F1-меры равно: 0.476, ROC_AUC: 0.763\n",
      "Модель: LogisticRegression(max_iter=10000, random_state=12345, solver='saga'), значение F1-меры равно: 0.476, ROC_AUC: 0.763\n",
      "\n",
      "Наилучшая модель: LogisticRegression(max_iter=10000, random_state=12345, solver='liblinear'), значение метрики F1 равно: 0.476, метрики ROC AUC: 0.763.\n"
     ]
    }
   ],
   "source": [
    "best_model_LogisticRegression = None\n",
    "best_result_valid = 0\n",
    "best_result_roc_auc = 0\n",
    "algoritms = ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "\n",
    "\n",
    "for alg in algoritms:\n",
    "\n",
    "    # определяем модель с заданным решающим алгоритмом и количеством итераций\n",
    "    model = LogisticRegression(random_state=12345, solver=alg, max_iter=10000)\n",
    "\n",
    "    model.fit(features_upsampled_scaled, target_upsampled) # обучаем модель\n",
    "\n",
    "    predictions_valid = model.predict(features_valid) # получаем предсказания модели\n",
    "\n",
    "    result_f1 = f1_score(target_valid, predictions_valid) # подсчитываем качество модели f1-мерой\n",
    "        \n",
    "    # расчитаем метрику ROC_AUC\n",
    "    probabilities = model.predict_proba(features_valid)\n",
    "    result_roc_auc = roc_auc_score(target_valid, probabilities[:, 1])\n",
    "    \n",
    "    print('Модель: {0}, значение F1-меры равно: {1}, ROC_AUC: {2}'. format(model, round(result_f1, 3), round(result_roc_auc, 3)))\n",
    "\n",
    "    if result_f1 > best_result_valid:\n",
    "        best_model_Logistic_Regression = model\n",
    "        best_result_valid = result_f1\n",
    "        best_result_roc_auc = result_roc_auc\n",
    "\n",
    "print()\n",
    "print('Наилучшая модель: {0}, значение метрики F1 равно: {1}, метрики ROC AUC: {2}.'. \n",
    "          format(best_model_Logistic_Regression, round(best_result_valid, 3), round(best_result_roc_auc, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "рост качества модели составил 44%\n"
     ]
    }
   ],
   "source": [
    "print('рост качества модели составил {0}%'. format(round(0.476 * 100 / 0.331 - 100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Чтож, ну хоть качество модели выросло). Стоит отметить, что рост качества модели получился самым существенным***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Итоги по сбалансированному обучению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Была произведена балансировка данных и масштабирование признаков.\n",
    "\n",
    "2) Обученные модели на новых данных показали результат лучше, чем до масштабирования.\n",
    "\n",
    "3) Модель `Логистической регрессии` так и не смогла пройти проверку на адекватность, что не может не удивлять."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дополнительное исследование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**По пробуем заменить кодировку OHE на Ordinal Encoding, которая больше подходит для моделей основаных на деревьях. Проверять будем на модели `Cлучайного леса`, так как она показывает самый лучший результат.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Кодирование признаков `Ordinal Encoding` и подготовка данных к обучению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5068.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>217.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>743.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5639.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>111.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5793.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5707.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>308.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4704.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>459.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3696.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3925.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>380.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4827.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>125.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5087.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>318.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2062.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>381.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>427.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4639.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>401.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4112.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1878.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Geography  Gender   Age  Tenure  Balance  NumOfProducts  \\\n",
       "0           228.0        0.0     0.0  24.0     2.0      0.0            0.0   \n",
       "1           217.0        2.0     0.0  23.0     1.0    743.0            0.0   \n",
       "2           111.0        0.0     0.0  24.0     8.0   5793.0            2.0   \n",
       "3           308.0        0.0     0.0  21.0     1.0      0.0            1.0   \n",
       "4           459.0        2.0     0.0  25.0     2.0   3696.0            0.0   \n",
       "...           ...        ...     ...   ...     ...      ...            ...   \n",
       "9995        380.0        0.0     1.0  21.0     5.0      0.0            1.0   \n",
       "9996        125.0        0.0     1.0  17.0    10.0    124.0            0.0   \n",
       "9997        318.0        0.0     0.0  18.0     7.0      0.0            0.0   \n",
       "9998        381.0        1.0     1.0  24.0     3.0    427.0            1.0   \n",
       "9999        401.0        0.0     0.0  10.0     5.0   4112.0            0.0   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0           1.0             1.0           5068.0     1.0  \n",
       "1           0.0             1.0           5639.0     0.0  \n",
       "2           1.0             0.0           5707.0     1.0  \n",
       "3           0.0             0.0           4704.0     0.0  \n",
       "4           1.0             1.0           3925.0     0.0  \n",
       "...         ...             ...              ...     ...  \n",
       "9995        1.0             0.0           4827.0     0.0  \n",
       "9996        1.0             1.0           5087.0     0.0  \n",
       "9997        0.0             1.0           2062.0     1.0  \n",
       "9998        1.0             0.0           4639.0     1.0  \n",
       "9999        1.0             0.0           1878.0     0.0  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Произведём порядковое кодирование признаков\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "data_ordinal = data.drop(['CustomerId', 'Surname', 'RowNumber'], axis=1)\n",
    "data_ordinal = pd.DataFrame(encoder.fit_transform(data_ordinal), columns=data_ordinal.columns)\n",
    "\n",
    "display(data_ordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделим снова наши данные\n",
    "ordinal_features_train, ordinal_target_train, ordinal_features_valid,  ordinal_target_valid, ordinal_features_test,  ordinal_target_test = train_valid_test_split(data_ordinal, \n",
    "                                        target = 'Exited', train_size=0.6, valid_size=0.2, test_size=0.2, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Произведём масштабирование данных\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(ordinal_features_train)\n",
    "\n",
    "ordinal_features_train_scaled = scaler.transform(ordinal_features_train)\n",
    "ordinal_features_valid_scaled = scaler.transform(ordinal_features_valid)\n",
    "ordinal_features_test_scaled = scaler.transform(ordinal_features_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Кодировка произведена, данные подготовлены, приступим к обучению модели.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение на новых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшая модель: RandomForestClassifier(max_depth=18, n_estimators=90, random_state=12345), значение метрики F1 равно: 0.582, метрики ROC AUC: 0.84.\n"
     ]
    }
   ],
   "source": [
    "best_model_Random_Forest_ordinal = None\n",
    "best_result_valid = 0\n",
    "best_result_roc_auc = 0\n",
    "\n",
    "for depth in range(1, 21):\n",
    "    for est in range(5, 101, 5):\n",
    "        \n",
    "        # определяем модель с заданными количеством и глубиной деревьев\n",
    "        model = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth)\n",
    "\n",
    "        model.fit(ordinal_features_train_scaled, ordinal_target_train) # обучаем модель\n",
    "\n",
    "        predictions_valid = model.predict(ordinal_features_valid_scaled) # получаем предсказания модели\n",
    "\n",
    "        result_f1 = f1_score(ordinal_target_valid, predictions_valid) # подсчитываем качество модели f1-мерой\n",
    "        # расчитаем метрику ROC_AUC\n",
    "        probabilities = model.predict_proba(ordinal_features_valid_scaled)\n",
    "        result_roc_auc = roc_auc_score(ordinal_target_valid, probabilities[:, 1])\n",
    "\n",
    "        if result_f1 > best_result_valid:\n",
    "            best_model_Random_Forest_ordinal = model\n",
    "            best_result_valid = result_f1\n",
    "            best_result_roc_auc = result_roc_auc\n",
    "\n",
    "print('Наилучшая модель: {0}, значение метрики F1 равно: {1}, метрики ROC AUC: {2}.'. \n",
    "      format(best_model_Random_Forest_ordinal, round(best_result_valid, 3), round(best_result_roc_auc, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Новая модель, обученная на данных с новой кодировкой, обучена и показала на валидационной выборке результат все-же хуже чем с прямым кодированием признаков.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пришло время протестировать самые лучшие из обученных моделей, модели `Случайного леса`, обученные на сбалансированных кодированных разными способами данных. Параметры модели с прямой кодировкой признаков: глубина - 11, число деревьев - 100; порядковой кодировкой: глубина - 18, число деревьев 90.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение F1-меры на тестовых данных равно: 0.606, ROC_AUC: 0.846\n"
     ]
    }
   ],
   "source": [
    "# Начнём итоговое тестирование\n",
    "\n",
    "# Вычислим предсказания модели\n",
    "predictions_test = best_model_Random_Forest_upsampled.predict(features_test)\n",
    "\n",
    "# вычислим значение F1-меры и ROC_AUC для тестовой выборки\n",
    "f1_score_test = f1_score(target_test, predictions_test)\n",
    "\n",
    "probabilities = best_model_Random_Forest_upsampled.predict_proba(features_valid)\n",
    "result_roc_auc_test = roc_auc_score(target_valid, probabilities[:, 1])\n",
    "\n",
    "print('Значение F1-меры на тестовых данных равно: {0}, ROC_AUC: {1}'.format(round(f1_score_test, 3), round(result_roc_auc_test, 3)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Вычислим предсказания модели\n",
    "predictions_test_ordinal = best_model_Random_Forest_ordinal.predict(ordinal_features_test_scaled)\n",
    "\n",
    "# вычислим значение F1-меры и ROC_AUC для тестовой выборки\n",
    "f1_score_test_ordinal = f1_score(ordinal_target_test, predictions_test_ordinal)\n",
    "result_roc_auc_test_ordinal = roc_auc_score(ordinal_target_test, predictions_test_ordinal)\n",
    "print('Значение F1-меры на тестовых данных равно: {0}, ROC_AUC: {1}'.format(round(f1_score_test_ordinal, 3), round(result_roc_auc_test_ordinal, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Как можем наблюдать, в конечном итоге прямое кодирование позволило обучить более качественную модель, которая прошла заданный в условии задачи рубеж 0.59. На этом этапе можем смело остановиться, потому что поставленные в проекте цели выполнены, найдена модель, обладающая достаточным качеством для решения заданной задачи.***\n",
    "\n",
    "P.S.: Я понимаю, что так было делать не правильно. Надо было найти лучшую на валидационной выборке и только потом тестировать ее, но соблазн сравнить был слишком велик))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**По пробуем посмотреть на значение метрики recall**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6784869976359338\n"
     ]
    }
   ],
   "source": [
    "# выведем результат сразу через print\n",
    "\n",
    "print(recall_score(target_test, predictions_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Если правильно всё понял, то модель предсказывает отток клиентов всего-лишь в 70% процентов случаев. И если это действительно так, то наша модель еще слишком далека от использования в реальной системе. Даже можно сказать ее противопоказанно использовать для решения данной задачи)). Надо дальше изучать, чтобы понять, что еще можно сделать для повышения качество предсказаний.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист готовности проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поставьте 'x' в выполненных пунктах. Далее нажмите Shift+Enter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Выполнен шаг 1: данные подготовлены\n",
    "- [x]  Выполнен шаг 2: задача исследована\n",
    "    - [x]  Исследован баланс классов\n",
    "    - [x]  Изучены модели без учёта дисбаланса\n",
    "    - [x]  Написаны выводы по результатам исследования\n",
    "- [x]  Выполнен шаг 3: учтён дисбаланс\n",
    "    - [x]  Применено несколько способов борьбы с дисбалансом\n",
    "    - [x]  Написаны выводы по результатам исследования\n",
    "- [x]  Выполнен шаг 4: проведено тестирование\n",
    "- [x]  Удалось достичь *F1*-меры не менее 0.59\n",
    "- [x]  Исследована метрика *AUC-ROC*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 589,
    "start_time": "2023-02-14T16:32:22.633Z"
   },
   {
    "duration": 14,
    "start_time": "2023-02-14T16:33:02.476Z"
   },
   {
    "duration": 65,
    "start_time": "2023-02-14T16:34:45.627Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-14T16:34:50.701Z"
   },
   {
    "duration": 8,
    "start_time": "2023-02-14T16:34:59.768Z"
   },
   {
    "duration": 8,
    "start_time": "2023-02-14T16:35:21.657Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-14T16:36:42.505Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-14T16:38:35.760Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-14T16:39:13.031Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-14T16:41:42.569Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-14T16:42:09.232Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-14T16:42:22.084Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-14T16:42:51.254Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-14T16:43:12.261Z"
   },
   {
    "duration": 9,
    "start_time": "2023-02-14T16:43:25.389Z"
   },
   {
    "duration": 414,
    "start_time": "2023-02-14T16:43:32.922Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-14T16:43:36.370Z"
   },
   {
    "duration": 65,
    "start_time": "2023-02-14T16:52:15.223Z"
   },
   {
    "duration": 49,
    "start_time": "2023-02-14T16:52:26.071Z"
   },
   {
    "duration": 1050,
    "start_time": "2023-02-14T17:01:52.311Z"
   },
   {
    "duration": 46,
    "start_time": "2023-02-14T17:04:50.788Z"
   },
   {
    "duration": 12,
    "start_time": "2023-02-14T17:04:56.913Z"
   },
   {
    "duration": 14,
    "start_time": "2023-02-14T17:05:35.123Z"
   },
   {
    "duration": 14,
    "start_time": "2023-02-14T17:06:00.489Z"
   },
   {
    "duration": 12,
    "start_time": "2023-02-14T17:06:17.749Z"
   },
   {
    "duration": 13,
    "start_time": "2023-02-14T17:06:25.960Z"
   },
   {
    "duration": 25,
    "start_time": "2023-02-14T17:06:41.369Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-14T17:14:23.707Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-14T17:14:37.822Z"
   },
   {
    "duration": 9,
    "start_time": "2023-02-14T17:19:55.845Z"
   },
   {
    "duration": 119,
    "start_time": "2023-02-14T17:38:51.005Z"
   },
   {
    "duration": 17,
    "start_time": "2023-02-14T17:38:58.828Z"
   },
   {
    "duration": 13,
    "start_time": "2023-02-14T17:39:39.816Z"
   },
   {
    "duration": 14,
    "start_time": "2023-02-14T17:39:47.409Z"
   },
   {
    "duration": 17,
    "start_time": "2023-02-14T17:40:05.633Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-14T17:47:35.547Z"
   },
   {
    "duration": 8,
    "start_time": "2023-02-14T17:47:44.925Z"
   },
   {
    "duration": 17,
    "start_time": "2023-02-14T18:04:39.557Z"
   },
   {
    "duration": 31,
    "start_time": "2023-02-14T18:04:50.431Z"
   },
   {
    "duration": 23,
    "start_time": "2023-02-14T18:04:58.055Z"
   },
   {
    "duration": 252,
    "start_time": "2023-02-14T18:07:04.902Z"
   },
   {
    "duration": 19,
    "start_time": "2023-02-14T18:07:59.101Z"
   },
   {
    "duration": 1360,
    "start_time": "2023-02-14T18:08:21.807Z"
   },
   {
    "duration": 57,
    "start_time": "2023-02-14T18:08:23.169Z"
   },
   {
    "duration": 14,
    "start_time": "2023-02-14T18:08:23.228Z"
   },
   {
    "duration": 41,
    "start_time": "2023-02-14T18:08:23.244Z"
   },
   {
    "duration": 49,
    "start_time": "2023-02-14T18:08:23.287Z"
   },
   {
    "duration": 11,
    "start_time": "2023-02-14T18:08:23.338Z"
   },
   {
    "duration": 34,
    "start_time": "2023-02-14T18:08:23.351Z"
   },
   {
    "duration": 55,
    "start_time": "2023-02-14T18:08:23.387Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-14T18:08:23.445Z"
   },
   {
    "duration": 21,
    "start_time": "2023-02-14T18:18:12.820Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-14T18:24:25.293Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-14T18:34:43.929Z"
   },
   {
    "duration": 3588,
    "start_time": "2023-02-14T18:46:30.332Z"
   },
   {
    "duration": 19,
    "start_time": "2023-02-14T18:46:45.252Z"
   },
   {
    "duration": 9,
    "start_time": "2023-02-14T18:48:35.232Z"
   },
   {
    "duration": 12,
    "start_time": "2023-02-14T18:48:52.730Z"
   },
   {
    "duration": 9,
    "start_time": "2023-02-14T18:49:22.155Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-14T18:49:28.880Z"
   },
   {
    "duration": 1494,
    "start_time": "2023-02-15T16:33:15.169Z"
   },
   {
    "duration": 202,
    "start_time": "2023-02-15T16:33:16.666Z"
   },
   {
    "duration": 14,
    "start_time": "2023-02-15T16:33:16.870Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-15T16:33:16.886Z"
   },
   {
    "duration": 19,
    "start_time": "2023-02-15T16:33:16.895Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-15T16:33:16.916Z"
   },
   {
    "duration": 8,
    "start_time": "2023-02-15T16:33:16.924Z"
   },
   {
    "duration": 50,
    "start_time": "2023-02-15T16:33:16.934Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-15T16:33:16.986Z"
   },
   {
    "duration": 30,
    "start_time": "2023-02-15T16:33:16.991Z"
   },
   {
    "duration": 137,
    "start_time": "2023-02-15T16:33:17.024Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-15T16:33:17.163Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-15T16:33:17.168Z"
   },
   {
    "duration": 1314,
    "start_time": "2023-02-15T16:33:45.667Z"
   },
   {
    "duration": 60,
    "start_time": "2023-02-15T16:33:46.982Z"
   },
   {
    "duration": 13,
    "start_time": "2023-02-15T16:33:47.043Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-15T16:33:47.058Z"
   },
   {
    "duration": 18,
    "start_time": "2023-02-15T16:33:47.066Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-15T16:33:47.086Z"
   },
   {
    "duration": 9,
    "start_time": "2023-02-15T16:33:47.095Z"
   },
   {
    "duration": 32,
    "start_time": "2023-02-15T16:33:47.106Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-15T16:33:47.140Z"
   },
   {
    "duration": 23,
    "start_time": "2023-02-15T16:33:47.166Z"
   },
   {
    "duration": 2938,
    "start_time": "2023-02-15T16:33:47.190Z"
   },
   {
    "duration": 11,
    "start_time": "2023-02-15T16:33:50.130Z"
   },
   {
    "duration": 24,
    "start_time": "2023-02-15T16:33:50.142Z"
   },
   {
    "duration": 434,
    "start_time": "2023-02-15T17:05:24.297Z"
   },
   {
    "duration": 119,
    "start_time": "2023-02-15T17:11:36.520Z"
   },
   {
    "duration": 474,
    "start_time": "2023-02-15T17:12:06.899Z"
   },
   {
    "duration": 1378,
    "start_time": "2023-02-15T17:12:39.947Z"
   },
   {
    "duration": 67,
    "start_time": "2023-02-15T17:12:41.327Z"
   },
   {
    "duration": 15,
    "start_time": "2023-02-15T17:12:41.396Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-15T17:12:41.413Z"
   },
   {
    "duration": 23,
    "start_time": "2023-02-15T17:12:41.422Z"
   },
   {
    "duration": 23,
    "start_time": "2023-02-15T17:12:41.446Z"
   },
   {
    "duration": 26,
    "start_time": "2023-02-15T17:12:41.472Z"
   },
   {
    "duration": 17,
    "start_time": "2023-02-15T17:12:41.500Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-15T17:12:41.519Z"
   },
   {
    "duration": 20,
    "start_time": "2023-02-15T17:12:41.524Z"
   },
   {
    "duration": 2307,
    "start_time": "2023-02-15T17:12:41.545Z"
   },
   {
    "duration": 23,
    "start_time": "2023-02-15T17:12:43.854Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-15T17:12:43.880Z"
   },
   {
    "duration": 460,
    "start_time": "2023-02-15T17:12:43.889Z"
   },
   {
    "duration": 108816,
    "start_time": "2023-02-15T17:12:44.351Z"
   },
   {
    "duration": 421,
    "start_time": "2023-02-15T17:15:01.950Z"
   },
   {
    "duration": 610,
    "start_time": "2023-02-15T17:18:43.069Z"
   },
   {
    "duration": 1857,
    "start_time": "2023-02-15T17:19:51.916Z"
   },
   {
    "duration": 27,
    "start_time": "2023-02-15T17:34:46.627Z"
   },
   {
    "duration": 33,
    "start_time": "2023-02-15T17:35:23.544Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-15T17:42:47.555Z"
   },
   {
    "duration": 138,
    "start_time": "2023-02-15T17:47:05.221Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-15T17:48:18.722Z"
   },
   {
    "duration": 3685,
    "start_time": "2023-02-15T17:48:26.188Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-15T17:48:49.271Z"
   },
   {
    "duration": 3654,
    "start_time": "2023-02-15T17:48:53.141Z"
   },
   {
    "duration": 121,
    "start_time": "2023-02-15T17:49:04.805Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-15T17:56:46.171Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-15T17:56:53.492Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-15T17:56:57.489Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-15T17:57:08.017Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-15T17:57:48.533Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-15T17:57:49.885Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-15T17:58:05.680Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-15T17:58:31.380Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-15T17:59:12.875Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-15T18:02:39.832Z"
   },
   {
    "duration": 45,
    "start_time": "2023-02-15T18:06:40.352Z"
   },
   {
    "duration": 27,
    "start_time": "2023-02-15T18:06:44.256Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-15T18:19:24.753Z"
   },
   {
    "duration": 14,
    "start_time": "2023-02-15T18:22:20.792Z"
   },
   {
    "duration": 694,
    "start_time": "2023-02-15T18:24:47.213Z"
   },
   {
    "duration": 9,
    "start_time": "2023-02-15T18:25:05.278Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-15T18:25:14.382Z"
   },
   {
    "duration": 557,
    "start_time": "2023-02-15T18:27:46.921Z"
   },
   {
    "duration": 9,
    "start_time": "2023-02-15T18:33:30.341Z"
   },
   {
    "duration": 524,
    "start_time": "2023-02-15T18:35:31.761Z"
   },
   {
    "duration": 141742,
    "start_time": "2023-02-15T18:38:51.369Z"
   },
   {
    "duration": 879,
    "start_time": "2023-02-15T18:44:38.800Z"
   },
   {
    "duration": 29,
    "start_time": "2023-02-15T18:51:52.831Z"
   },
   {
    "duration": 1605,
    "start_time": "2023-02-16T16:28:36.490Z"
   },
   {
    "duration": 182,
    "start_time": "2023-02-16T16:28:38.097Z"
   },
   {
    "duration": 16,
    "start_time": "2023-02-16T16:28:38.281Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-16T16:28:38.300Z"
   },
   {
    "duration": 25,
    "start_time": "2023-02-16T16:28:38.309Z"
   },
   {
    "duration": 9,
    "start_time": "2023-02-16T16:28:38.336Z"
   },
   {
    "duration": 13,
    "start_time": "2023-02-16T16:28:38.346Z"
   },
   {
    "duration": 21,
    "start_time": "2023-02-16T16:28:38.361Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-16T16:28:38.384Z"
   },
   {
    "duration": 53,
    "start_time": "2023-02-16T16:28:38.390Z"
   },
   {
    "duration": 3233,
    "start_time": "2023-02-16T16:28:38.445Z"
   },
   {
    "duration": 14,
    "start_time": "2023-02-16T16:28:41.680Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-16T16:28:41.696Z"
   },
   {
    "duration": 415,
    "start_time": "2023-02-16T16:28:41.703Z"
   },
   {
    "duration": 116241,
    "start_time": "2023-02-16T16:28:42.120Z"
   },
   {
    "duration": 667,
    "start_time": "2023-02-16T16:30:38.363Z"
   },
   {
    "duration": 195,
    "start_time": "2023-02-16T16:30:39.034Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-16T16:30:39.231Z"
   },
   {
    "duration": 3908,
    "start_time": "2023-02-16T16:30:39.237Z"
   },
   {
    "duration": 133,
    "start_time": "2023-02-16T16:30:43.147Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-16T16:30:43.281Z"
   },
   {
    "duration": 26,
    "start_time": "2023-02-16T16:30:43.287Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-16T16:30:43.315Z"
   },
   {
    "duration": 11,
    "start_time": "2023-02-16T16:30:43.324Z"
   },
   {
    "duration": 592,
    "start_time": "2023-02-16T16:30:43.338Z"
   },
   {
    "duration": 156758,
    "start_time": "2023-02-16T16:30:43.932Z"
   },
   {
    "duration": 751,
    "start_time": "2023-02-16T16:33:20.692Z"
   },
   {
    "duration": 195,
    "start_time": "2023-02-16T16:33:21.447Z"
   },
   {
    "duration": 2042,
    "start_time": "2023-02-16T16:37:10.574Z"
   },
   {
    "duration": 1311,
    "start_time": "2023-02-16T16:37:17.009Z"
   },
   {
    "duration": 59,
    "start_time": "2023-02-16T16:37:18.323Z"
   },
   {
    "duration": 14,
    "start_time": "2023-02-16T16:37:18.384Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-16T16:37:18.400Z"
   },
   {
    "duration": 23,
    "start_time": "2023-02-16T16:37:18.410Z"
   },
   {
    "duration": 9,
    "start_time": "2023-02-16T16:37:18.435Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-16T16:37:18.446Z"
   },
   {
    "duration": 20,
    "start_time": "2023-02-16T16:37:18.458Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-16T16:37:18.480Z"
   },
   {
    "duration": 53,
    "start_time": "2023-02-16T16:37:18.485Z"
   },
   {
    "duration": 2161,
    "start_time": "2023-02-16T16:37:18.540Z"
   },
   {
    "duration": 25,
    "start_time": "2023-02-16T16:37:20.703Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-16T16:37:20.729Z"
   },
   {
    "duration": 411,
    "start_time": "2023-02-16T16:37:20.738Z"
   },
   {
    "duration": 111439,
    "start_time": "2023-02-16T16:37:21.151Z"
   },
   {
    "duration": 1246,
    "start_time": "2023-02-16T16:39:12.591Z"
   },
   {
    "duration": 183,
    "start_time": "2023-02-16T16:39:13.839Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-16T16:39:14.024Z"
   },
   {
    "duration": 3701,
    "start_time": "2023-02-16T16:39:14.031Z"
   },
   {
    "duration": 149,
    "start_time": "2023-02-16T16:39:17.734Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-16T16:39:17.885Z"
   },
   {
    "duration": 14,
    "start_time": "2023-02-16T16:39:17.891Z"
   },
   {
    "duration": 17,
    "start_time": "2023-02-16T16:39:17.907Z"
   },
   {
    "duration": 13,
    "start_time": "2023-02-16T16:39:17.925Z"
   },
   {
    "duration": 552,
    "start_time": "2023-02-16T16:39:17.940Z"
   },
   {
    "duration": 157583,
    "start_time": "2023-02-16T16:39:18.494Z"
   },
   {
    "duration": 759,
    "start_time": "2023-02-16T16:41:56.079Z"
   },
   {
    "duration": 216,
    "start_time": "2023-02-16T16:41:56.842Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-16T16:57:01.732Z"
   },
   {
    "duration": 41,
    "start_time": "2023-02-16T17:01:16.109Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-16T17:05:01.540Z"
   },
   {
    "duration": 11,
    "start_time": "2023-02-16T17:07:11.228Z"
   },
   {
    "duration": 137,
    "start_time": "2023-02-16T17:09:46.810Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-16T17:09:54.116Z"
   },
   {
    "duration": 15,
    "start_time": "2023-02-16T17:09:54.729Z"
   },
   {
    "duration": 13,
    "start_time": "2023-02-16T17:12:00.166Z"
   },
   {
    "duration": 3278,
    "start_time": "2023-02-16T17:12:24.474Z"
   },
   {
    "duration": 1472,
    "start_time": "2023-02-16T17:22:05.209Z"
   },
   {
    "duration": 56,
    "start_time": "2023-02-16T17:22:06.683Z"
   },
   {
    "duration": 14,
    "start_time": "2023-02-16T17:22:06.740Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-16T17:22:06.757Z"
   },
   {
    "duration": 22,
    "start_time": "2023-02-16T17:22:06.767Z"
   },
   {
    "duration": 30,
    "start_time": "2023-02-16T17:22:06.791Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-16T17:22:06.823Z"
   },
   {
    "duration": 19,
    "start_time": "2023-02-16T17:22:06.831Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-16T17:22:06.852Z"
   },
   {
    "duration": 31,
    "start_time": "2023-02-16T17:22:06.857Z"
   },
   {
    "duration": 2264,
    "start_time": "2023-02-16T17:22:06.891Z"
   },
   {
    "duration": 17,
    "start_time": "2023-02-16T17:22:09.158Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-16T17:22:09.177Z"
   },
   {
    "duration": 433,
    "start_time": "2023-02-16T17:22:09.185Z"
   },
   {
    "duration": 115278,
    "start_time": "2023-02-16T17:22:09.620Z"
   },
   {
    "duration": 934,
    "start_time": "2023-02-16T17:24:04.900Z"
   },
   {
    "duration": 95,
    "start_time": "2023-02-16T17:24:05.837Z"
   },
   {
    "duration": 98,
    "start_time": "2023-02-16T17:24:05.934Z"
   },
   {
    "duration": 3677,
    "start_time": "2023-02-16T17:24:06.034Z"
   },
   {
    "duration": 128,
    "start_time": "2023-02-16T17:24:09.713Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-16T17:24:09.843Z"
   },
   {
    "duration": 14,
    "start_time": "2023-02-16T17:24:09.849Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-16T17:24:09.864Z"
   },
   {
    "duration": 15,
    "start_time": "2023-02-16T17:24:09.871Z"
   },
   {
    "duration": 563,
    "start_time": "2023-02-16T17:24:09.889Z"
   },
   {
    "duration": 157498,
    "start_time": "2023-02-16T17:24:10.454Z"
   },
   {
    "duration": 1371,
    "start_time": "2023-02-16T17:26:47.954Z"
   },
   {
    "duration": 129,
    "start_time": "2023-02-16T17:26:49.328Z"
   },
   {
    "duration": 8,
    "start_time": "2023-02-16T17:26:49.458Z"
   },
   {
    "duration": 11,
    "start_time": "2023-02-16T17:26:49.468Z"
   },
   {
    "duration": 121544,
    "start_time": "2023-02-16T17:26:49.481Z"
   },
   {
    "duration": 55,
    "start_time": "2023-02-16T17:28:51.027Z"
   },
   {
    "duration": 67,
    "start_time": "2023-02-16T17:28:51.084Z"
   },
   {
    "duration": 52,
    "start_time": "2023-02-16T17:29:44.178Z"
   },
   {
    "duration": 1382,
    "start_time": "2023-02-16T18:11:22.379Z"
   },
   {
    "duration": 59,
    "start_time": "2023-02-16T18:11:23.763Z"
   },
   {
    "duration": 13,
    "start_time": "2023-02-16T18:11:23.824Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-16T18:11:23.840Z"
   },
   {
    "duration": 23,
    "start_time": "2023-02-16T18:11:23.849Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-16T18:11:23.874Z"
   },
   {
    "duration": 39,
    "start_time": "2023-02-16T18:11:23.882Z"
   },
   {
    "duration": 19,
    "start_time": "2023-02-16T18:11:23.922Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-16T18:11:23.943Z"
   },
   {
    "duration": 29,
    "start_time": "2023-02-16T18:11:23.948Z"
   },
   {
    "duration": 2323,
    "start_time": "2023-02-16T18:11:23.978Z"
   },
   {
    "duration": 19,
    "start_time": "2023-02-16T18:11:26.302Z"
   },
   {
    "duration": 20,
    "start_time": "2023-02-16T18:11:26.322Z"
   },
   {
    "duration": 452,
    "start_time": "2023-02-16T18:11:26.344Z"
   },
   {
    "duration": 118397,
    "start_time": "2023-02-16T18:11:26.798Z"
   },
   {
    "duration": 320,
    "start_time": "2023-02-16T18:13:25.197Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T18:13:25.521Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T18:13:25.522Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T18:13:25.523Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T18:13:25.525Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T18:13:25.526Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T18:13:25.527Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T18:13:25.528Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T18:13:25.529Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T18:13:25.530Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T18:13:25.531Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T18:13:25.533Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T18:13:25.533Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T18:13:25.535Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T18:13:25.536Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T18:13:25.537Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T18:13:25.538Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T18:13:25.540Z"
   },
   {
    "duration": 1432,
    "start_time": "2023-02-16T18:19:34.654Z"
   },
   {
    "duration": 60,
    "start_time": "2023-02-16T18:19:36.088Z"
   },
   {
    "duration": 14,
    "start_time": "2023-02-16T18:19:36.150Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-16T18:19:36.166Z"
   },
   {
    "duration": 18,
    "start_time": "2023-02-16T18:19:36.175Z"
   },
   {
    "duration": 31,
    "start_time": "2023-02-16T18:19:36.195Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-16T18:19:36.228Z"
   },
   {
    "duration": 21,
    "start_time": "2023-02-16T18:19:36.237Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-16T18:19:36.260Z"
   },
   {
    "duration": 57,
    "start_time": "2023-02-16T18:19:36.265Z"
   },
   {
    "duration": 2439,
    "start_time": "2023-02-16T18:19:36.324Z"
   },
   {
    "duration": 15,
    "start_time": "2023-02-16T18:19:38.765Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-16T18:19:38.782Z"
   },
   {
    "duration": 483,
    "start_time": "2023-02-16T18:19:38.790Z"
   },
   {
    "duration": 114626,
    "start_time": "2023-02-16T18:19:39.274Z"
   },
   {
    "duration": 323,
    "start_time": "2023-02-16T18:21:33.902Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T18:21:34.227Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T18:21:34.228Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T18:21:34.230Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T18:21:34.231Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T18:21:34.232Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T18:21:34.233Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T18:21:34.235Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T18:21:34.236Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T18:21:34.237Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T18:21:34.238Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T18:21:34.239Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T18:21:34.240Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T18:21:34.241Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T18:21:34.243Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T18:21:34.244Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T18:21:34.245Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-16T18:21:34.246Z"
   },
   {
    "duration": 1342,
    "start_time": "2023-02-16T18:23:28.256Z"
   },
   {
    "duration": 62,
    "start_time": "2023-02-16T18:23:29.601Z"
   },
   {
    "duration": 15,
    "start_time": "2023-02-16T18:23:29.665Z"
   },
   {
    "duration": 8,
    "start_time": "2023-02-16T18:23:29.683Z"
   },
   {
    "duration": 40,
    "start_time": "2023-02-16T18:23:29.693Z"
   },
   {
    "duration": 8,
    "start_time": "2023-02-16T18:23:29.735Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-16T18:23:29.745Z"
   },
   {
    "duration": 21,
    "start_time": "2023-02-16T18:23:29.756Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-16T18:23:29.781Z"
   },
   {
    "duration": 26,
    "start_time": "2023-02-16T18:23:29.820Z"
   },
   {
    "duration": 2337,
    "start_time": "2023-02-16T18:23:29.848Z"
   },
   {
    "duration": 15,
    "start_time": "2023-02-16T18:23:32.187Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-16T18:23:32.203Z"
   },
   {
    "duration": 469,
    "start_time": "2023-02-16T18:23:32.221Z"
   },
   {
    "duration": 118184,
    "start_time": "2023-02-16T18:23:32.692Z"
   },
   {
    "duration": 958,
    "start_time": "2023-02-16T18:25:30.878Z"
   },
   {
    "duration": 186,
    "start_time": "2023-02-16T18:25:31.838Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-16T18:25:32.026Z"
   },
   {
    "duration": 3938,
    "start_time": "2023-02-16T18:25:32.031Z"
   },
   {
    "duration": 137,
    "start_time": "2023-02-16T18:25:35.971Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-16T18:25:36.110Z"
   },
   {
    "duration": 14,
    "start_time": "2023-02-16T18:25:36.121Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-16T18:25:36.137Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-16T18:25:36.143Z"
   },
   {
    "duration": 609,
    "start_time": "2023-02-16T18:25:36.155Z"
   },
   {
    "duration": 156371,
    "start_time": "2023-02-16T18:25:36.766Z"
   },
   {
    "duration": 800,
    "start_time": "2023-02-16T18:28:13.139Z"
   },
   {
    "duration": 218,
    "start_time": "2023-02-16T18:28:13.943Z"
   },
   {
    "duration": 9,
    "start_time": "2023-02-16T18:28:14.162Z"
   },
   {
    "duration": 11,
    "start_time": "2023-02-16T18:28:14.173Z"
   },
   {
    "duration": 122816,
    "start_time": "2023-02-16T18:28:14.185Z"
   },
   {
    "duration": 64,
    "start_time": "2023-02-16T18:30:17.003Z"
   },
   {
    "duration": 60,
    "start_time": "2023-02-16T18:30:17.069Z"
   },
   {
    "duration": 53,
    "start_time": "2023-02-16T18:31:29.609Z"
   },
   {
    "duration": 51,
    "start_time": "2023-02-16T18:31:36.127Z"
   },
   {
    "duration": 61,
    "start_time": "2023-02-18T08:01:29.361Z"
   },
   {
    "duration": 1719,
    "start_time": "2023-02-18T08:24:05.978Z"
   },
   {
    "duration": 206,
    "start_time": "2023-02-18T08:24:07.700Z"
   },
   {
    "duration": 14,
    "start_time": "2023-02-18T08:24:12.035Z"
   },
   {
    "duration": 20,
    "start_time": "2023-02-18T08:24:14.250Z"
   },
   {
    "duration": 8,
    "start_time": "2023-02-18T08:24:16.769Z"
   },
   {
    "duration": 8,
    "start_time": "2023-02-18T08:24:19.056Z"
   },
   {
    "duration": 37,
    "start_time": "2023-02-18T08:24:21.046Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-18T08:24:24.521Z"
   },
   {
    "duration": 3956,
    "start_time": "2023-02-18T08:24:29.667Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-18T08:25:31.681Z"
   },
   {
    "duration": 2513,
    "start_time": "2023-02-18T08:25:32.585Z"
   },
   {
    "duration": 8,
    "start_time": "2023-02-18T08:26:31.923Z"
   },
   {
    "duration": 8,
    "start_time": "2023-02-18T08:27:12.955Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-18T08:27:36.966Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-18T08:27:45.181Z"
   },
   {
    "duration": 22,
    "start_time": "2023-02-18T08:37:45.936Z"
   },
   {
    "duration": 8,
    "start_time": "2023-02-18T08:39:12.593Z"
   },
   {
    "duration": 13,
    "start_time": "2023-02-18T08:39:14.682Z"
   },
   {
    "duration": 25,
    "start_time": "2023-02-18T08:39:18.137Z"
   },
   {
    "duration": 7036,
    "start_time": "2023-02-18T08:43:31.823Z"
   },
   {
    "duration": 8,
    "start_time": "2023-02-18T08:43:47.067Z"
   },
   {
    "duration": 23,
    "start_time": "2023-02-18T08:43:47.913Z"
   },
   {
    "duration": 18,
    "start_time": "2023-02-18T08:43:50.792Z"
   },
   {
    "duration": 1276,
    "start_time": "2023-02-18T08:44:13.720Z"
   },
   {
    "duration": 60,
    "start_time": "2023-02-18T08:44:16.371Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-18T08:44:24.991Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-18T08:44:29.163Z"
   },
   {
    "duration": 2412,
    "start_time": "2023-02-18T08:44:33.689Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-18T08:44:36.105Z"
   },
   {
    "duration": 128,
    "start_time": "2023-02-18T08:44:36.300Z"
   },
   {
    "duration": 1215,
    "start_time": "2023-02-18T08:44:47.338Z"
   },
   {
    "duration": 58,
    "start_time": "2023-02-18T08:44:48.735Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-18T08:44:56.549Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-18T08:45:00.361Z"
   },
   {
    "duration": 2401,
    "start_time": "2023-02-18T08:45:01.196Z"
   },
   {
    "duration": 2358,
    "start_time": "2023-02-18T08:45:06.124Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-18T08:45:08.485Z"
   },
   {
    "duration": 122,
    "start_time": "2023-02-18T08:45:08.746Z"
   },
   {
    "duration": 1316,
    "start_time": "2023-02-18T08:49:48.602Z"
   },
   {
    "duration": 58,
    "start_time": "2023-02-18T08:49:49.920Z"
   },
   {
    "duration": 16,
    "start_time": "2023-02-18T08:49:49.983Z"
   },
   {
    "duration": 8,
    "start_time": "2023-02-18T08:49:50.001Z"
   },
   {
    "duration": 60,
    "start_time": "2023-02-18T08:49:50.011Z"
   },
   {
    "duration": 9,
    "start_time": "2023-02-18T08:49:50.073Z"
   },
   {
    "duration": 31,
    "start_time": "2023-02-18T08:49:50.084Z"
   },
   {
    "duration": 55,
    "start_time": "2023-02-18T08:49:50.117Z"
   },
   {
    "duration": 22,
    "start_time": "2023-02-18T08:49:50.175Z"
   },
   {
    "duration": 18,
    "start_time": "2023-02-18T08:49:50.199Z"
   },
   {
    "duration": 2607,
    "start_time": "2023-02-18T08:49:50.219Z"
   },
   {
    "duration": 2480,
    "start_time": "2023-02-18T08:49:52.829Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-18T08:49:55.311Z"
   },
   {
    "duration": 238,
    "start_time": "2023-02-18T08:49:55.319Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-18T08:49:55.559Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-18T08:49:55.560Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-18T08:49:55.562Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-18T08:49:55.563Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-18T08:49:55.564Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-18T08:49:55.565Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-18T08:49:55.566Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-18T08:49:55.567Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-18T08:49:55.568Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-18T08:49:55.570Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-18T08:49:55.571Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-18T08:49:55.572Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-18T08:49:55.573Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-18T08:49:55.574Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-18T08:49:55.575Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-18T08:49:55.577Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-18T08:49:55.578Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-18T08:49:55.579Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-18T08:49:55.580Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-18T08:49:55.581Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-18T08:49:55.582Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-18T08:49:55.583Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-18T09:00:37.589Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-18T09:00:42.753Z"
   },
   {
    "duration": 35,
    "start_time": "2023-02-18T09:01:26.329Z"
   },
   {
    "duration": 27,
    "start_time": "2023-02-18T09:01:28.851Z"
   },
   {
    "duration": 1353,
    "start_time": "2023-02-18T09:01:49.926Z"
   },
   {
    "duration": 61,
    "start_time": "2023-02-18T09:01:52.922Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-18T09:01:59.755Z"
   },
   {
    "duration": 33,
    "start_time": "2023-02-18T09:02:04.498Z"
   },
   {
    "duration": 2387,
    "start_time": "2023-02-18T09:02:07.876Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-18T09:02:13.735Z"
   },
   {
    "duration": 134,
    "start_time": "2023-02-18T09:02:15.437Z"
   },
   {
    "duration": 31,
    "start_time": "2023-02-18T09:02:58.444Z"
   },
   {
    "duration": 26,
    "start_time": "2023-02-18T09:03:07.372Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-18T09:03:16.620Z"
   },
   {
    "duration": 53,
    "start_time": "2023-02-18T09:03:21.331Z"
   },
   {
    "duration": 23,
    "start_time": "2023-02-18T09:03:24.226Z"
   },
   {
    "duration": 582,
    "start_time": "2023-02-18T09:04:51.681Z"
   },
   {
    "duration": 20,
    "start_time": "2023-02-18T09:06:11.225Z"
   },
   {
    "duration": 21,
    "start_time": "2023-02-18T09:06:14.923Z"
   },
   {
    "duration": 571,
    "start_time": "2023-02-18T09:07:19.752Z"
   },
   {
    "duration": 13,
    "start_time": "2023-02-18T09:07:44.520Z"
   },
   {
    "duration": 510,
    "start_time": "2023-02-18T09:08:03.834Z"
   },
   {
    "duration": 596,
    "start_time": "2023-02-18T09:09:02.255Z"
   },
   {
    "duration": 1248,
    "start_time": "2023-02-18T09:09:06.871Z"
   },
   {
    "duration": 71,
    "start_time": "2023-02-18T09:09:08.122Z"
   },
   {
    "duration": 17,
    "start_time": "2023-02-18T09:09:08.195Z"
   },
   {
    "duration": 35,
    "start_time": "2023-02-18T09:09:08.214Z"
   },
   {
    "duration": 52,
    "start_time": "2023-02-18T09:09:08.251Z"
   },
   {
    "duration": 28,
    "start_time": "2023-02-18T09:09:08.304Z"
   },
   {
    "duration": 32,
    "start_time": "2023-02-18T09:09:08.334Z"
   },
   {
    "duration": 42,
    "start_time": "2023-02-18T09:09:08.368Z"
   },
   {
    "duration": 35,
    "start_time": "2023-02-18T09:09:08.412Z"
   },
   {
    "duration": 60,
    "start_time": "2023-02-18T09:09:08.450Z"
   },
   {
    "duration": 2341,
    "start_time": "2023-02-18T09:09:08.512Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-18T09:09:10.855Z"
   },
   {
    "duration": 61,
    "start_time": "2023-02-18T09:09:10.862Z"
   },
   {
    "duration": 33,
    "start_time": "2023-02-18T09:09:10.925Z"
   },
   {
    "duration": 595,
    "start_time": "2023-02-18T09:09:10.960Z"
   },
   {
    "duration": 139,
    "start_time": "2023-02-18T09:09:11.556Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-18T09:09:11.697Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-18T09:09:11.698Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-18T09:09:11.700Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-18T09:09:11.701Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-18T09:09:11.703Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-18T09:09:11.704Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-18T09:09:11.706Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-18T09:09:11.708Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-18T09:09:11.709Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-18T09:09:11.710Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-18T09:09:11.712Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-18T09:09:11.713Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-18T09:09:11.738Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-18T09:09:11.739Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-18T09:09:11.740Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-18T09:09:11.742Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-18T09:09:11.743Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-18T09:09:11.744Z"
   },
   {
    "duration": 128746,
    "start_time": "2023-02-18T09:13:35.056Z"
   },
   {
    "duration": 1258,
    "start_time": "2023-02-18T09:17:30.281Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-18T09:22:44.823Z"
   },
   {
    "duration": 8,
    "start_time": "2023-02-18T09:23:10.883Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-18T09:23:59.593Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-18T09:24:03.918Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-18T09:24:18.076Z"
   },
   {
    "duration": 14,
    "start_time": "2023-02-18T09:32:43.645Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-18T09:32:51.361Z"
   },
   {
    "duration": 8,
    "start_time": "2023-02-18T09:32:52.749Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-18T09:32:54.634Z"
   },
   {
    "duration": 8,
    "start_time": "2023-02-18T09:32:55.434Z"
   },
   {
    "duration": 19,
    "start_time": "2023-02-18T09:32:56.965Z"
   },
   {
    "duration": 20,
    "start_time": "2023-02-18T09:33:12.975Z"
   },
   {
    "duration": 651,
    "start_time": "2023-02-18T09:33:21.789Z"
   },
   {
    "duration": 181543,
    "start_time": "2023-02-18T09:33:59.696Z"
   },
   {
    "duration": 1191,
    "start_time": "2023-02-18T09:38:06.855Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-18T09:41:04.944Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-18T09:41:50.101Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-18T09:42:01.832Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-18T09:42:16.128Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-18T09:42:18.879Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-18T09:42:25.328Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-18T09:42:31.749Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-18T09:42:37.236Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-18T09:42:41.745Z"
   },
   {
    "duration": 79,
    "start_time": "2023-02-18T09:42:58.097Z"
   },
   {
    "duration": 46,
    "start_time": "2023-02-18T09:43:03.730Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-18T09:43:07.200Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-18T09:43:54.835Z"
   },
   {
    "duration": 17,
    "start_time": "2023-02-18T09:44:59.684Z"
   },
   {
    "duration": 11,
    "start_time": "2023-02-18T09:46:16.954Z"
   },
   {
    "duration": 111,
    "start_time": "2023-02-18T09:46:29.641Z"
   },
   {
    "duration": 95,
    "start_time": "2023-02-18T09:46:39.255Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-18T10:00:19.935Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-18T10:01:02.204Z"
   },
   {
    "duration": 1193,
    "start_time": "2023-02-18T10:08:18.104Z"
   },
   {
    "duration": 59,
    "start_time": "2023-02-18T10:08:19.299Z"
   },
   {
    "duration": 14,
    "start_time": "2023-02-18T10:08:19.360Z"
   },
   {
    "duration": 13,
    "start_time": "2023-02-18T10:08:19.377Z"
   },
   {
    "duration": 26,
    "start_time": "2023-02-18T10:08:19.392Z"
   },
   {
    "duration": 18,
    "start_time": "2023-02-18T10:08:19.420Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-18T10:08:19.439Z"
   },
   {
    "duration": 26,
    "start_time": "2023-02-18T10:08:19.447Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-18T10:08:19.475Z"
   },
   {
    "duration": 27,
    "start_time": "2023-02-18T10:08:19.481Z"
   },
   {
    "duration": 2275,
    "start_time": "2023-02-18T10:08:19.510Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-18T10:08:21.787Z"
   },
   {
    "duration": 48,
    "start_time": "2023-02-18T10:08:21.794Z"
   },
   {
    "duration": 18,
    "start_time": "2023-02-18T10:08:21.845Z"
   },
   {
    "duration": 569,
    "start_time": "2023-02-18T10:08:21.865Z"
   },
   {
    "duration": 129591,
    "start_time": "2023-02-18T10:08:22.438Z"
   },
   {
    "duration": 1024,
    "start_time": "2023-02-18T10:10:32.031Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-18T10:10:33.139Z"
   },
   {
    "duration": 3757,
    "start_time": "2023-02-18T10:10:33.239Z"
   },
   {
    "duration": 148,
    "start_time": "2023-02-18T10:10:36.997Z"
   },
   {
    "duration": 8,
    "start_time": "2023-02-18T10:10:37.147Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-18T10:10:37.157Z"
   },
   {
    "duration": 30,
    "start_time": "2023-02-18T10:10:37.170Z"
   },
   {
    "duration": 11,
    "start_time": "2023-02-18T10:10:37.202Z"
   },
   {
    "duration": 20,
    "start_time": "2023-02-18T10:10:37.215Z"
   },
   {
    "duration": 670,
    "start_time": "2023-02-18T10:10:37.237Z"
   },
   {
    "duration": 176378,
    "start_time": "2023-02-18T10:10:37.909Z"
   },
   {
    "duration": 1351,
    "start_time": "2023-02-18T10:13:34.288Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-18T10:13:35.642Z"
   },
   {
    "duration": 86,
    "start_time": "2023-02-18T10:13:35.739Z"
   },
   {
    "duration": 8,
    "start_time": "2023-02-18T10:13:35.827Z"
   },
   {
    "duration": 20,
    "start_time": "2023-02-18T10:13:35.837Z"
   },
   {
    "duration": 157,
    "start_time": "2023-02-18T10:13:35.859Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-18T10:13:36.018Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-18T10:13:36.019Z"
   },
   {
    "duration": 137279,
    "start_time": "2023-02-18T10:15:26.760Z"
   },
   {
    "duration": 126,
    "start_time": "2023-02-18T10:25:42.477Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-18T10:25:48.425Z"
   },
   {
    "duration": 1291,
    "start_time": "2023-02-18T10:26:00.019Z"
   },
   {
    "duration": 61,
    "start_time": "2023-02-18T10:26:01.313Z"
   },
   {
    "duration": 15,
    "start_time": "2023-02-18T10:26:01.375Z"
   },
   {
    "duration": 72,
    "start_time": "2023-02-18T10:26:01.391Z"
   },
   {
    "duration": 61,
    "start_time": "2023-02-18T10:26:01.465Z"
   },
   {
    "duration": 37,
    "start_time": "2023-02-18T10:26:01.527Z"
   },
   {
    "duration": 37,
    "start_time": "2023-02-18T10:26:01.565Z"
   },
   {
    "duration": 56,
    "start_time": "2023-02-18T10:26:01.604Z"
   },
   {
    "duration": 29,
    "start_time": "2023-02-18T10:26:01.662Z"
   },
   {
    "duration": 41,
    "start_time": "2023-02-18T10:26:01.693Z"
   },
   {
    "duration": 2520,
    "start_time": "2023-02-18T10:26:01.736Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-18T10:26:04.258Z"
   },
   {
    "duration": 54,
    "start_time": "2023-02-18T10:26:04.265Z"
   },
   {
    "duration": 23,
    "start_time": "2023-02-18T10:26:04.322Z"
   },
   {
    "duration": 663,
    "start_time": "2023-02-18T10:26:04.347Z"
   },
   {
    "duration": 131116,
    "start_time": "2023-02-18T10:26:05.012Z"
   },
   {
    "duration": 1510,
    "start_time": "2023-02-18T10:28:16.129Z"
   },
   {
    "duration": 97,
    "start_time": "2023-02-18T10:28:17.641Z"
   },
   {
    "duration": 3801,
    "start_time": "2023-02-18T10:28:17.740Z"
   },
   {
    "duration": 145,
    "start_time": "2023-02-18T10:28:21.543Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-18T10:28:21.690Z"
   },
   {
    "duration": 9,
    "start_time": "2023-02-18T10:28:21.699Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-18T10:28:21.710Z"
   },
   {
    "duration": 19,
    "start_time": "2023-02-18T10:28:21.721Z"
   },
   {
    "duration": 13,
    "start_time": "2023-02-18T10:28:21.742Z"
   },
   {
    "duration": 637,
    "start_time": "2023-02-18T10:28:21.757Z"
   },
   {
    "duration": 177852,
    "start_time": "2023-02-18T10:28:22.396Z"
   },
   {
    "duration": 4689,
    "start_time": "2023-02-18T10:31:20.251Z"
   },
   {
    "duration": 95,
    "start_time": "2023-02-18T10:31:24.942Z"
   },
   {
    "duration": 53,
    "start_time": "2023-02-18T10:31:25.039Z"
   },
   {
    "duration": 9,
    "start_time": "2023-02-18T10:31:25.094Z"
   },
   {
    "duration": 33,
    "start_time": "2023-02-18T10:31:25.105Z"
   },
   {
    "duration": 139181,
    "start_time": "2023-02-18T10:31:25.140Z"
   },
   {
    "duration": 124,
    "start_time": "2023-02-18T10:33:44.323Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-18T10:33:44.449Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "366.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
